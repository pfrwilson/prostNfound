import math
import warnings

import matplotlib.pyplot as plt
import numpy as np
import torch
import wandb
from tqdm import tqdm
import logging
import random
import numpy as np
import torch
import itertools
from abc import ABC, abstractmethod
from typing import Literal, Sequence
import pandas as pd
from sklearn.metrics import (
    balanced_accuracy_score,
    f1_score,
    recall_score,
    roc_auc_score,
    roc_curve,
)
import matplotlib.pyplot as plt



def _no_grad_trunc_normal_(tensor, mean, std, a, b):
    # Cut & paste from PyTorch official master until it's in a few official releases - RW
    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf
    def norm_cdf(x):
        # Computes standard normal cumulative distribution function
        return (1.0 + math.erf(x / math.sqrt(2.0))) / 2.0

    if (mean < a - 2 * std) or (mean > b + 2 * std):
        warnings.warn(
            "mean is more than 2 std from [a, b] in nn.init.trunc_normal_. "
            "The distribution of values may be incorrect.",
            stacklevel=2,
        )

    with torch.no_grad():
        # Values are generated by using a truncated uniform distribution and
        # then using the inverse CDF for the normal distribution.
        # Get upper and lower cdf values
        l = norm_cdf((a - mean) / std)
        u = norm_cdf((b - mean) / std)

        # Uniformly fill tensor with values from [l, u], then translate to
        # [2l-1, 2u-1].
        tensor.uniform_(2 * l - 1, 2 * u - 1)

        # Use inverse cdf transform for normal distribution to get truncated
        # standard normal
        tensor.erfinv_()

        # Transform to proper mean, std
        tensor.mul_(std * math.sqrt(2.0))
        tensor.add_(mean)

        # Clamp to ensure it's in the proper range
        tensor.clamp_(min=a, max=b)
        return tensor


def trunc_normal_(tensor, mean=0.0, std=1.0, a=-2.0, b=2.0):
    # type: (Tensor, float, float, float, float) -> Tensor
    return _no_grad_trunc_normal_(tensor, mean, std, a, b)


def calculate_metrics(predictions, labels, log_images=False):
    """Calculate metrics for the cancer classification problem.

    Args:
        predictions (np.array or torch.Tensor) - A column vector of predicted probabilities for
            cancer (1) or benign(0)
        labels (np.array or torch.Tensor) - A column vector of true labels for cancer (1) or benign(0)
        log_images (bool) - If True, log images of the histogram of predictions and the ROC curve to
            wandb. Default is False.
    """

    if isinstance(predictions, torch.Tensor):
        predictions = predictions.cpu().numpy()
    if isinstance(labels, torch.Tensor):
        labels = labels.cpu().numpy()

    # augmentations can cause NaNs
    nanvalues = np.isnan(predictions)
    predictions = predictions[~nanvalues]
    labels = labels[~nanvalues]

    
    metrics = {}

    # core predictions
    core_probs = predictions
    core_labels = labels
    metrics["auc"] = roc_auc_score(core_labels, core_probs)

    # find the sensitivity at fixed specificities
    fpr, tpr, thresholds = roc_curve(core_labels, core_probs)

    for specificity in [0.20, 0.40, 0.60, 0.80]:
        sensitivity = tpr[np.argmax(fpr > 1 - specificity)]
        metrics[f"sens_at_{specificity*100:.0f}_spe"] = sensitivity

    # choose the threshold that maximizes balanced accuracy
    best_threshold = thresholds[np.argmax(tpr - fpr)]
    metrics["f1"] = f1_score(core_labels, core_probs > best_threshold)

    if log_images:
        plt.hist(core_probs[core_labels == 0], bins=100, alpha=0.5, density=True)
        plt.hist(core_probs[core_labels == 1], bins=100, alpha=0.5, density=True)
        plt.legend(["Benign", "Cancer"])
        plt.xlabel(f"Probability of cancer")
        plt.ylabel("Density")
        plt.title(f"AUC: {metrics['auc']:.3f}")
        metrics["histogram"] = wandb.Image(plt, caption="Histogram of core predictions")
        plt.close()

        plt.figure()
        plt.plot(fpr, tpr)
        plt.xlabel("False positive rate")
        plt.ylabel("True positive rate")
        plt.title("ROC curve")
        metrics["roc_curve"] = wandb.Image(plt, caption="ROC curve")
        plt.close()

    return metrics


class PatchView:
    """A class representing a view of an image as a collection of patches.

    Access patches through the [] operator.

    Args:
        image (array-like): The image to be viewed as patches. If the image is 2D, it is assumed to be grayscale.
            If the image is 3D, it is assumed to be RGB, with the last dimension being the color channel.
        positions (array-like): A list of positions of the patches. Each position is a list of 4 integers:
            [x1, y1, x2, y2], where (x1, y1) is the top left corner of the patch and (x2, y2) is the bottom right corner.
    """

    _cache = {}

    def __init__(self, image, positions):
        self.image = image
        self.positions = positions

    def __getitem__(self, index):
        x1, y1, x2, y2 = self.positions[index]

        return self.image[x1:x2, y1:y2]

    def __len__(self):
        return len(self.positions)

    @staticmethod
    def _sliding_window_positions(image_size, window_size, stride, align_to="topleft"):
        """
        Generate a list of positions for a sliding window over an image.

        Args:
            image_size (tuple): The size of the image.
            window_size (tuple): The size of the sliding window.
            stride (tuple): The stride of the sliding window.
            align_to (str): The alignment of the sliding window. Can be one of: ['topleft', 'bottomleft', 'topright', 'bottomright'].

        Returns:
            positions (array-like): A list of positions of the patches. Each position is a list of 4 integers:
                [x1, y1, x2, y2], where (x1, y1) is the top left corner of the patch and (x2, y2) is the bottom right corner.
        """

        if (image_size, window_size, stride, align_to) not in PatchView._cache:
            if len(image_size) == 2:
                x, y = image_size
            else:
                x, y, _ = image_size

            k1, k2 = window_size
            s1, s2 = stride

            positions = np.mgrid[0 : x - k1 + 1 : s1, 0 : y - k2 + 1 : s2]

            # if the last window is not flush with the image, we may need to offset the image slightly
            lastx, lasty = positions[:, -1, -1]
            lastx += k1
            lasty += k2
            if "bottom" in align_to:
                positions[0, :, :] += x - lastx
            if "right" in align_to:
                positions[1, :, :] += y - lasty

            positions = positions.reshape(2, -1).T
            positions = np.concatenate([positions, positions + window_size], axis=1)

            PatchView._cache[(image_size, window_size, stride, align_to)] = positions

        return PatchView._cache[(image_size, window_size, stride, align_to)]

    @staticmethod
    def from_sliding_window(
        image, window_size, stride, align_to="topleft", masks=[], thresholds=[]
    ):
        """Generate a PatchView from a sliding window over an image.

        This factory method can be used to generate a PatchView from a sliding window over an image.
        The sliding window can be filtered by a list of masks. If the mean of the mask in a window is greater than the corresponding threshold, the window is kept.

        Args:
            image (array-like): The image to be viewed as patches.
                If the image is 2D, it is assumed to be grayscale;
                if the image is 3D, it is assumed to be RGB, with the last dimension being the color channel.
            window_size (tuple): The size of the sliding window.
            stride (tuple): The stride of the sliding window.
            align_to (str): The alignment of the sliding window. Can be one of: ['topleft', 'bottomleft', 'topright', 'bottomright'].
            masks (array-like): A list of masks to apply to the sliding window. If the mean of the mask in a window is greater than the corresponding threshold, the window is kept.
                The masks should be 2-dimensional.
            thresholds (array-like): A list of thresholds for the masks.

        Returns:
            PatchView: A PatchView object.

        """
        positions = PatchView._sliding_window_positions(
            image.shape, window_size, stride, align_to=align_to
        )

        for mask, threshold in zip(masks, thresholds):
            filtered_positions = []
            for x1, y1, x2, y2 in positions:
                X, Y = image.shape[:2]
                X_mask, Y_mask = mask.shape[:2]

                # if the mask is of a different shape than the image,
                # we need to adjust the coordinates to be relative to the mask
                if X != X_mask:
                    x1_mask = int(x1 / X * X_mask)
                    x2_mask = int(x2 / X * X_mask)
                else:
                    x1_mask, x2_mask = x1, x2
                if Y != Y_mask:
                    y1_mask = int(y1 / Y * Y_mask)
                    y2_mask = int(y2 / Y * Y_mask)
                else:
                    y1_mask, y2_mask = y1, y2

                if np.mean(mask[x1_mask:x2_mask, y1_mask:y2_mask]) >= threshold:
                    filtered_positions.append([x1, y1, x2, y2])

            positions = np.array(filtered_positions)

        return PatchView(image, positions)

    @staticmethod
    def build_collection_from_images_and_masks(
        image_list,
        window_size,
        stride,
        align_to="topleft",
        mask_lists=[],
        thresholds=[],
    ):
        """Generate a collection of PatchViews from a collection of images and masks.

        Because this will vectorize the mask intersection calculations, it is much faster than calling from_sliding_window multiple times.
        However, this method requires that all images and masks are of the same size.

        Args:
            image_list (array-like): A list of images to be viewed as patches.
                If the images are 2D, they are assumed to be grayscale;
                if the images are 3D, they are assumed to be RGB, with the last dimension being the color channel.
            window_size (tuple): The size of the sliding window.
            stride (tuple): The stride of the sliding window.
            align_to (str): The alignment of the sliding window. Can be one of: ['topleft', 'bottomleft', 'topright', 'bottomright'].
            mask_lists (array-like): A list of lists of masks to apply to the sliding window. If the mean of the mask in a window is greater
                than the corresponding threshold, the window is kept. The masks should be 2-dimensional. If more then one list of masks is provided,
                they will be applied in order to filter the windows.
            thresholds (array-like): A list of thresholds for the masks.
        """

        n_images = len(image_list)
        H, W = image_list[0].shape[:2]
        position_candidates = PatchView._sliding_window_positions(
            image_list[0].shape, window_size, stride, align_to=align_to
        )

        n_position_candidates = len(position_candidates)
        valid_position_candidates = np.ones(
            (n_images, n_position_candidates), dtype=bool
        )

        for mask_list, threshold in zip(mask_lists, thresholds):
            valid_position_candidates_for_mask = np.zeros(
                (n_images, n_position_candidates), dtype=bool
            )
            mask_arr = np.stack(mask_list, axis=-1)

            for idx in tqdm(range(n_position_candidates), desc="Applying mask"):
                x1, y1, x2, y2 = position_candidates[idx]
                x1 = int(x1 / H * mask_arr.shape[0])
                x2 = int(x2 / H * mask_arr.shape[0])
                y1 = int(y1 / W * mask_arr.shape[1])
                y2 = int(y2 / W * mask_arr.shape[1])

                valid_position_candidates_for_mask[:, idx] = (
                    mask_arr[x1:x2, y1:y2].mean(axis=(0, 1)) > threshold
                )

            valid_position_candidates *= valid_position_candidates_for_mask

        patch_views = []
        for idx in tqdm(range(n_images), desc="Filtering positions"):
            positions_for_image = []
            for j in range(n_position_candidates):
                if valid_position_candidates[idx, j]:
                    position = position_candidates[j]
                    positions_for_image.append(position)

            patch_views.append(PatchView(image_list[idx], positions_for_image))

        return patch_views

    def show(self, ax=None):
        """Show the patch view by plotting the patches on top of the image.

        Args:
            ax (matplotlib.axes.Axes): The axes to plot on. If None, a new figure and axes is created.
        """

        if ax is None:
            fig, ax = plt.subplots()

        image = self.image
        ax.imshow(image, cmap="gray" if image.ndim == 2 else None)
        for x1, y1, x2, y2 in self.positions:
            ax.plot([y1, y2, y2, y1, y1], [x1, x1, x2, x2, x1], "r")
        ax.axis("off")
        return ax


def set_global_seed(seed):

    logging.info(f"Setting global seed to {seed}")
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)

    # set deterministic cudnn
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


def get_all_rng_states():
    return {
        "random": random.getstate(),
        "numpy": np.random.get_state(),
        "torch_cpu": torch.get_rng_state(),
        "torch_cuda": torch.cuda.get_rng_state_all(),
    }


def set_all_rng_states(rng_states):
    logging.info("Setting all RNG states")
    random.setstate(rng_states["random"])
    np.random.set_state(rng_states["numpy"])
    torch.set_rng_state(rng_states["torch_cpu"])
    torch.cuda.set_rng_state_all(rng_states["torch_cuda"])


def cosine_scheduler(
    base_value, final_value, epochs, niter_per_ep, warmup_epochs=0, start_warmup_value=0
):
    warmup_schedule = np.array([])
    warmup_iters = warmup_epochs * niter_per_ep
    if warmup_epochs > 0:
        warmup_schedule = np.linspace(start_warmup_value, base_value, warmup_iters)

    iters = np.arange(epochs * niter_per_ep - warmup_iters)
    schedule = final_value + 0.5 * (base_value - final_value) * (
        1 + np.cos(np.pi * iters / len(iters))
    )

    schedule = np.concatenate((warmup_schedule, schedule))
    assert len(schedule) == epochs * niter_per_ep
    return schedule


class Accumulator(ABC):
    @abstractmethod
    def __call__(self, value): ...

    @abstractmethod
    def reset(self): ...

    @abstractmethod
    def compute(self): ...

    def __repr__(self):
        return f"{self.__class__.__name__}({self.compute()})"


class Average(Accumulator):
    def __init__(self):
        self.reset()

    def __call__(self, value):
        self.sum += value
        self.count += 1
        return self.sum / self.count

    def reset(self):
        self.sum = 0
        self.count = 0

    def compute(self):
        return self.sum / self.count


class ExponentialMovingAverage(Accumulator):
    def __init__(self, alpha=0.9):
        self.reset()
        self.alpha = alpha

    def __call__(self, value):
        self.value = self.alpha * self.value + (1 - self.alpha) * value
        return self.value

    def reset(self):
        self.value = 0

    def compute(self):
        return self.value


class MovingAverage(Accumulator):
    def __init__(self, window_size=10):
        self.reset()
        self.window_size = window_size

    def __call__(self, value):
        self.values.append(value)
        if len(self.values) > self.window_size:
            self.values.pop(0)
        return sum(self.values) / len(self.values)

    def reset(self):
        self.values = []

    def compute(self):
        return sum(self.values) / len(self.values)


class Max(Accumulator):
    def __init__(self):
        self.reset()

    def __call__(self, value):
        self.value = max(self.value, value)
        return self.value

    def reset(self):
        self.value = 0

    def compute(self):
        return self.value


class Sum(Accumulator):
    def __init__(self):
        self.reset()

    def __call__(self, value):
        self.value += value
        return self.value

    def reset(self):
        self.value = 0

    def compute(self):
        return self.value


class DictConcatenation(Accumulator):
    def __init__(self):
        self.reset()

    def __call__(self, data_dict):

        for k, v in data_dict.items():
            if isinstance(v, torch.Tensor):
                v = v.detach().cpu()
            elif isinstance(v, np.ndarray):
                pass
            elif not isinstance(v, Sequence):
                v = [v]
            self._data.setdefault(k, []).append(v)

    def update(self, data_dict):
        self(data_dict)

    def compute(self, out_fmt: Literal["dict", "dataframe"] = "dict"):
        out = {}
        for k, v in self._data.items():
            out[k] = (
                torch.concat(v)
                if isinstance(v[0], torch.Tensor)
                else list(itertools.chain(*v))
            )

        for k, v in out.items():
            if isinstance(v, list):
                out[k] = np.array(v)

        if out_fmt == "dict":
            return out

        else:
            out_new = {}
            for k, v in out.items():
                if isinstance(v, torch.Tensor):
                    v = v.detach().cpu().numpy()
                if isinstance(v, np.ndarray) and v.ndim == 2:
                    for i in range(v.shape[1]):
                        out_new[f"{k}_{i}"] = v[:, i]
                else:
                    out_new[k] = v
            return pd.DataFrame(out_new)

    def reset(self):
        self._data = {}


class DataFrameCollector(DictConcatenation):
    def compute(self):
        return super().compute(out_fmt="dataframe")
